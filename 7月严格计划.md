7月总规划：
7.1 - 7.8
- qwen2.5vl 模型适配  7.1-7.2
 - 模型代码更改 7.1
 - 模型微调 7.2
 - 撰写10分钟汇报ppt 7.1晚-7.2上 done

- 视频流数据集构造 7.3

- UI agent数据集构造 7.4-7.5
 - 数据集筛选+过滤 7.4
 - segement 优化 + 应用数据集 7.5

7.6-7.8
 - 获取 2*3的result，并且进行优化；争取生成合适的结果(需考虑每个组件的time cost)
 - 三个技术点报告
 - 若Qwen2.5vl效果不行，换成其他的比如Qwen2vl、phi3v


每周时间安排：
早9-12点 3h
下午2:30-6:00 3.5h
晚上7:30-10:30 3.5h



qwen2.5vl 模型适配 - 模型代码更改
- 获取分割mask  2点前完成  done
    - 与image相同size done
    - 通过args.printImage   打印出PIL image 与 mask，确认mask的效果是否一致 done
- 继承Qwen2.5vl的processor
    - 继承Qwen2.5vl的processor、继承Qwen2VLImageProcessor的image_processor done
    - mask 与 image格式一致 done
        - 省略了 mask与input数据内容能一一匹配
    - 重新定义两个类，并重写其两个model    done
    - masks 与 2D-rope的映射
        - 理解2D-rope的生成逻辑
        - 确认full_qwen_pos_ids_tensor中data顺序与patch_indices顺序是一致的
            - rope的生成是独立于pixel_values生成的，是根据grid_thw生成的；所以，rope和image、mask理论上都是基于 Qwen独特的顺序生成的。
            - 缺乏验证
    - windows-attention 
        - 先看下 Qwen2.5vl 如何进行的windows-attention
        - 考虑按照原有的方式进行windows-attention，但是通过indices进行过滤
            - 以112个像素作为一个windows，每个windows的规格可能不同。
        - 这里留个待完成：可以考虑按照windows-attention的粒度来对图片切分为背景和前景
    - 测试验证
        - 流程 done


写一篇处理逻辑的心得总结：










7.1 晚 - 7.2 上午:
撰写10分钟汇报ppt
- 背景：2024级普博 / 目前的研究方向 / 已发表论文:
- 介绍当前研究工作
- 总结：工作进展 / 下一步预计投稿




13-15 代码适配完成
15-16 验证evaluation



undo:
16-18 确认finetune 方式
17-22 数据集更改、finetune成功
22-23 确认deepcache所用数据集


10-11 确认finetune 方式
11-12 数据集格式更改
13-14 确认evaluation 跑通
14-16 finetune代码，流程跑通
16-18 收集视频流数据集、deepcache数据集


19-21 测试视频流数据集 result


1. 10点确认视频流数据集
2. 评测数据集验证



- 验证视频流评估数据集
- 

- 视频流数据集测评




undo:
- 视频流评估数据集




- Qwen基于原始llava的数据集result [15:30前]  
    - evaluation 评估流程打通
        - 应该以llava现有实现为主，更改为调用qwen2.5vl的模型
        - finetune后也调用 qwen2.5vl的模型





- 释放nanhu的2个gpu 进行Qwenfinetune [16:30前]
    - finetune Qwen2.5vl模型 

- 迁移环境至 beiyou
    - dataset done
    - model done
    - conda env
    - source code


- llava [20:00 前]
    - 适配原始数据集 pope，给出结果
    - 适配不使用数据集的情况下，其result

- llava for video数据集 [22:00 前]
    - 



- 将模型迁移至 autodl, 4*1 模型来运行



- 将模型迁移至beiyou，为什么网络不行？？ 考虑直接整个clash过去

