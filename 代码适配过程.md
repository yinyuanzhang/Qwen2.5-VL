1.视频流的问题确认下  [验证下视频流缓存的result]
2.segment + prompt 是否切割效果会好。
3.linxiaozhu + ragcache 看看文章写法
4.张老师论文审稿   6.28 下午4-6点


- vqa数据集验证下效果 / 根据gqa测试其accuracy
- 视频流数据集验证效果 accuracy


环境：
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121

目标：3个模型 * 3个数据集
1. qwen2.5 的推理流程  能够完整运行   done

python run_mmmu.py infer \
    --model-path Qwen/Qwen2.5-VL-3B-Instruct \
    --data-dir ./mmmu \
    --dataset MMMU_DEV_VAL \
    --output-file results/mmmu_dev_val_predictions.jsonl


2. 先看看qwen的推理流程(图像预处理、图像位置、模型结构与逻辑)
图像位置：交互式图像位置image 与 text 交互
图像预处理：是否做了resize，如何实现的 -> self.processor实现
模型结构：vit + llm(相对不用关心)


forward 理解模型的基础上，再去更改整体的模型逻辑 [自定义vit & 自定义获取image feature 的forward流程]
- 7点前完成理解
- 8点半前完成模型改写



今晚目标：完成上述结构改变
- 通过 arg参数实现
- arg不启用，不改变原有逻辑；arg启用，采用背景和目标分离的方式

上午：[早上8点开始]
- 进一步理解qwen的vit处理逻辑，想办法将其改为 背景 + 目标双vit的格式
- 基于上述 更改后的格式添加参数，确保不影响效果
- 验证下现有的evaluation

下午：
- 基于知乎/其他资料，尝试一次finetune

晚上：
- 审稿
- 基于llava的数据集实现finetuen并运行。








3. 按照知乎走一遍 qwen2.5vl 的微调流程  /  用llama_factory完成微调
- 尝试微调一下，即便不用llava的微调数据集






4. 数据集换为 视频流，其result(明天尽量完成)


5. 数据集换为 ui agent数据集，其result(后天尽量完成;  尽量先完成2 model*3 dataset吧[也就是])






原始图片 -> resize之后的图片 -> yolov8 的输入要求 -> yolov8 mask之后的图片 -> 输入到vit之前的图片

vit内部如何对图片进行处理：
- rope-2D
- 



1. embedding之外对图片的处理，resize？ 到底经历了什么。

将图像处理后的Img.PIL，通过yolov8进行处理，返回与Img.PIL相同大小的mask；
将mask与图像均通过 preprocess 进行处理。


2. 需要在本地实现类，继承远程的调用。

需要给其一段全新的prompt，加上明确的指示和做法。
- 参数
- 确保一一对应
- 图片分割
- 图片patch


任务拆解：
- 获取图片mask
- 根据mask获取bg_patch 和 fg_patch
- bg_patch 和 fg_patch 全局编码信息
- bg_patch 和 fg_patch 



2模型(llava-1.5v-7b、 qwen2.5vl-3b、 模型) * 3数据集(generation、ui agent、video)

qwen2.5vl 模型适配 - 模型代码更改
- 获取分割mask    done
    - 与image相同size done
    - 通过args.printImage   打印出PIL image 与 mask，确认mask的效果是否一致 done
- 继承Qwen2.5vl的processor
    - resize done
    - 2D-rope done
    - windows-attention done
- finetune
    - 流程 donw
    - llava 数据集 


ui agent数据集
- Androidcontrol
    - filter [基于像素过滤] done
    - mask 



视频流数据集
- SEED-Bench-video-image
- deepcache



整个故事点
三个技术点  技术点的   challenge、insights [围绕challenge]




7.1 - 7.8
- qwen2.5vl 模型适配  7.1-7.2
 - 模型代码更改 7.1
 - 模型微调 7.2

- 视频流数据集构造 7.3

- UI agent数据集构造 7.4-7.5
 - 数据集筛选+过滤 7.4
 - segement 优化 + 应用数据集 7.5

7.6-7.8
- 获取 2*3的result，并且进行优化；争取生成合适的结果(需考虑每个组件的time cost)








finetune 代码分析：
- load 方式没有提供state_dict()
- max-pixels、merge_size等参数传入
- 是否需要filter[相当比例数据是没有image的]]

- model done
- data
- mask
- train
- train param






- debug

-- model evaluation
看 image、mask 结构

-- origin model train 
看 image 如何处理

-- model train
看 image 和 mask 如何处理，如何串联
一步步看image 处理流程

8:30-11:30
+ 逐步验证
+ 确保逻辑无误












