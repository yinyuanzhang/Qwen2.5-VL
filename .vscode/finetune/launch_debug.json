{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Distributed Training (Master Process Debug)",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/qwenvl/train/train_qwen.py", // 你的 entry_file
            "console": "integratedTerminal", // 或 "internalConsole"
            "justMyCode": false, // 允许调试第三方库代码，对于深度学习通常很有用
            "env": {
                // Distributed training configuration (mimicking torchrun env)
                "MASTER_ADDR": "127.0.0.1",
                // Generate a random port for MASTER_PORT, or fix it for consistent debugging
                "MASTER_PORT": "20001", // You might want to fix this to a specific port for debugging
                "NNODES": "1", // Assuming single node debugging
                "NPROC_PER_NODE": "4", // Assuming 4 GPUs are conceptually available for the "master" process if it were truly distributed
                // CUDA/PyTorch specific environment variables
                "CUDA_VISIBLE_DEVICES": "4,5,6,7", // Debugging will use these GPUs if available and specified
                "PYTORCH_CUDA_ALLOC_CONF": "expandable_segments:True",
                "LD_LIBRARY_PATH": "/data/zyy/cuda-11.8/libcurand/targets/x86_64-linux/lib:${env:LD_LIBRARY_PATH}",
                // For DeepSpeed, ensure it can find its configuration
                "DS_BUILD_OPS": "1" // Often needed for DeepSpeed custom ops compilation
            },
            "args": [
                "--deepspeed", "./scripts/zero3.json",
                "--model_name_or_path", "Qwen/Qwen2.5-VL-3B-Instruct",
                "--dataset_use", "llava",
                "--data_flatten", "True",
                "--tune_mm_vision", "False",
                "--tune_mm_mlp", "True",
                "--tune_mm_llm", "True",
                "--bf16",
                "--output_dir", "./output",
                "--num_train_epochs", "0.5",
                "--per_device_train_batch_size", "4",
                "--per_device_eval_batch_size", "8", // 4*2
                "--gradient_accumulation_steps", "4",
                "--max_pixels", "50176",
                "--min_pixels", "784",
                "--eval_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps", "1000",
                "--save_total_limit", "1",
                "--learning_rate", "2e-7",
                "--weight_decay", "0",
                "--warmup_ratio", "0.03",
                "--max_grad_norm", "1",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--model_max_length", "8192",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "4",
                "--run_name", "qwen2vl-baseline",
                "--report_to", "wandb",
                "--use_image_segmentation", "True", // Boolean value is passed as string "True" or "False"
                "--yolo_model_path", "/data/zyy/LLaVA/checkpoints/yolov/yolov8l-seg.pt"
            ],
            // Specify the Python interpreter used for debugging
            // Make sure this path points to the 'bagle' conda environment's python
            "python": "/data/yinyuan/conda_env/bagle/bin/python"
        }
    ]
}