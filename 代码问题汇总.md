timeline：
Mobicom2025
- 8.29 

Mobicom2024
- 8.18

7.12 finetune Qwen2.5vl-3B
7.13 video dataset result
7.14 ui agent dataset result  Security海报
7.15-7.16 Qwen2vl-2B

争取7.18/7.25 前完成 3*3 accuracy、time cost


问题:

1. 数据集中出现 不包含 images的数据实例

# === Modification Start ===
# Filter out samples that do not contain 'image' key right after loading
initial_total_samples = len(list_data_dict)
list_data_dict = [sample for sample in list_data_dict if "image" in sample]
rank0_print(f"Filtered to {len(list_data_dict)} samples (only those with 'image'). Removed {initial_total_samples - len(list_data_dict)} samples.")
# === Modification End ===

2. 保留原始的finetune代码，确认一下现有的Qwen2.5vl-finetune之后，运行pope的结果 ing[3、4节点]




3. 原生Qwen2.5vl finetune代码理解
- Qwen2_5_VLProcessor 与 CustomQwen2_5_VLProcessor 的区别
    - Qwen2_5_VLProcessor 仅仅是封装了 image_processor 和 tokenizer
    - Inference时：CustomQwen2_5_VLProcessor中forward 从image交给 image_processor处理 改为了 把mask和image交给 image_processor处理
    - Finetune时：模型没有用到 Qwen2_5_VLProcessor，直接定义的 Image_processor，相当于forward相关操作外移了


4. model save
- ./output 肯定不行，需要save到 /data/yinyuan/output 目录下

- Watchdog caught collective operation timeout: WorkNCCL(SeqNum=220472, OpType=_ALLGATHER_BASE, NumelIn=155582464, NumelOut=311164928, Timeout(ms)=1800000) ran for 1800091 milliseconds before timing out.
    - 原因：
[rank0]:[E712 19:15:46.098418596 ProcessGroupNCCL.cpp:664] Stack trace of the failed collective: 
#0 all_gather from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:3704
#1 wrapper from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:81
#2 distributed_broadcast_scalars from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:230
#3 store_flos from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer.py:4009
#4 _save_checkpoint from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer.py:3193
#5 _maybe_log_save_evaluate from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer.py:3100
#6 _inner_training_loop from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer.py:2620
#7 train from /data/yinyuan/conda_env/qwen2/lib/python3.10/site-packages/transformers/trainer.py:2245
#8 train from /home/zyy/tmp/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py:168
#9 <module> from /home/zyy/tmp/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py:178
    - 解决：1. 分片保存 2. 增加time cost  
    - 原因：有可能是save时需要将 running out of memory issue since it needs to collects the model's weights to memory.





5. mask 命名和取值问题
- mask 类型应该为 bool类型
- mask 取值用 flatten() 还是用 .any(dim=1)


6. 运行速度问题
- segement 分解是否运行在GPU？

import torch.multiprocessing as mp # 导入 multiprocessing 模块

# =========================================================================
# 关键步骤：在任何 PyTorch 或 multiprocessing 相关代码之前设置启动方法
# 这必须在 DataLoader 或任何 CUDA 操作之前完成。
try:
    mp.set_start_method('spawn', force=True)
    print("多进程启动方法已设置为 'spawn'。")
except RuntimeError:
    # 如果已经设置过（例如被某个库设置），这里会捕获错误，可以忽略
    print("多进程启动方法已设置。")
# =========================================================================

7. 数据准确性
- 数据为 list等，mask是如何处理的
- mask实现逻辑patch是否合理
- 先背景、再前景的向量拼接方式是否符合


- 适配llava数据集
    - 



8. 运行过程报错  2%就报错
- 运行过程中报超时
    缓解方案：改为 yolov8s模型


9. 代码确认(只考虑代码，不考虑device相关问题)：
- mmmu数据集下确认逻辑是否正确 [模型加载、数据预处理、逻辑patch设计、背景在前，前景在后的特征拼接]  2h
- pope数据集下 
    -- 无分割模式下速度多快
    -- 有分割模式下速度；数据集处理和llava是否一致；如何过滤为只有
- finetune模式下
    -- 数据预处理是否合理



10. 模型结构
- Qwen2_5_VLProcessor [其作用完全是为了完成图片的数据预处理，模型不是其调用的，和其也无关系]
    - Qwen2VLImageProcessor
        - Qwen2_5_VisionTransformerPretrainedModel
            - preprocess
    - _call_ 中调用 image_processor


- model.process_vision_info
    - fetch_Image 实现PIL.Image的resize
    - [segement] 相当于实现 self.processor() 处理前实现 mask与image相同size和格式(PIL.Image),基于fetch_Image的实现result
    - 边界点：1. 没有图片 2. 多张图片

undo: 补充case，是常见coco图片



- Qwen2_5_VLForConditionalGeneration
    - Qwen2_5_VisionTransformerPretrainedModel
        - patch_embed
        - window_size
        - rotary_pos_emb

    - Qwen2_5_VLModel

    - def get_rope_index
    - def forward



    - CustomQwen2_5_VLForConditionalGeneration
        - def forward(masks)





to do list:
- 确认mmmu代码无误 [争取16:00前]
- 确认infer代码无误 [争取17:00前]
- 确认finetune代码无误 [争取19:00前]  待确认
- pope 数据集result [争取21:00前]
- 改写 qwen2VL






11. Accuracy 结果差距很大
- evaluation 代码应该不存在问题 [模型一致、只是拆分了背景和前景，怎么效果差异这么大？ 微调后的模型，效果确实变好了一些。]
- 可能存在的问题：1. 背景和前景不连续[可以考虑以窗口为单位验证下效果] 应该会有提升。   2. 代码存在问题[特征拼接与合并]  3. 位置编码应用不对，完全错乱了。
    4. too many images 是什么情况？ 多张image是什么原因？
- 有没有什么办法能追踪 / 验证？ 类似测试代码

肯定有问题，同样的模型，只不过切割了而已，效果怎么可能差异这么大！！！


入手点：不考虑finetuned后的模型，只以origin模型为出发点进行考量(以避免微调模型不对带来的误差)。
初步怀疑两个问题：
1. rope位置编码未对齐
2. windows窗口大小需一致


- 第一步：查看现有的窗口分配是否合理
    - 能否保证现有的窗口内各patch的排列顺序呢
    - 如果不行的话，我们改为以窗口为单位进行mask分割，看看效果
    - 目前始终怀疑：每个向量与其rope并未一一对应

- 第二步：确认ROPE有无问题
    - 原始的ROPE到底是如何做的，哪里起作用？
    - 不论某向量在哪里窗口内，其ROPE都应该使用的同一个
    - 如何验证呢？

- 第三步：直接将整个模型一分为二，理论来说应该不会有太大accuracy差异。




12. 加载模型的device和dtype是如何决定的






13. 现有Qwen2.5vl 如何处理 rope编码、logic patch、windows attention
- 数据预处理
    - process_vision_info [resize(按照28*28进行数据预处理，只是resize，不进行任何padding)]
    - Processor -> Qwen2VLImageProcessor [do_resize / do_rescale / do_normalize] -> 复制temporal_patch_size次（默认为2）
    - image:[grid_t(1) * grid_h * grid_w, patch_size(14) * patch_size(14) * temporal_patch_size(2) * channels]

    - 按照logical patch处理：patches = patches.transpose(0, 3, 6, 4, 7, 2, 1, 5, 8)



- 动态分辨率
    - resize为28的倍数，边缘填充 [logical patch的大小就是28*28，但是为什么还要分为physical patch？]
        - logical patch的数目是最终的token数目，logical patch内部的physical patch会进行合并
    - 高分辨率图片会导致patch数目极其大，增加推理时间
    [启发：我们的论文也可以定义logical patch作为 背景和前景的mask]
        - merge
        - windows attention

    [https://zhuanlan.zhihu.com/p/25267823390]

- rope位置编码
    - 


- windows-attention
    - 4层全注意力，其余windows注意力
    - 窗口8*8(112*112)，小于该size不填充





验证：
把背景在前，前景在后 分离以后我们再重新





原始代码两个问题：
1. windows_index到底是什么[代表一种序列，针对上一序列的排序顺序]，如何划分；transformer如何区分哪个windows，通过seqlens

2. 如何把windows_index 重排回去的？



- 窗口数可能为奇数么




- 还是效果不好：
    - 验证1: 核心的forward代码不变，看result是否有变化来看是外部/内部因素影响
    - 验证2：mask 随机抽取1-2个，看最终的result是否有大幅度变化
    - 验证3：完整的向量截取一部分看最终的result 




- 如何调研Qwen2-vl
    - 能够新添加一个github仓库，如果不可以的话，那就只能 git clone了
    - 同一套环境env
    - 深入debug探究模型的推理流程
    - 加载模型
    - 自定义mllm推理流程
    - 适配pope数据集，给出推理result即可。


