研究现状与进展：

模型*3:
llava-1.5v-7b
Qwen2.5vl-3b [Qwen2vl-2b]
Qwen2vl-2b[resize、]
phine3v

数据集*3:
pope-vqa
self-driving [目前是未微调版本]
AndroidControl

device*3



Qwen2.5vl-3b(pope-vqa)  92.3(origin)/88.2(background-based)  原因: resize后无法对应一致   background-rate 63.7% 



tips: 如果局部注意力，听起来challenge[insights??]


补充energy 的metric



undo:
1. 3*3的accuracy result
[接下来主要耗时在数据集的适配、筛选]

2. time cost
[主要是mllm侧端到端的集成，最初版本是先不考虑accuracy的time cost]

3. 优化
- finetune
- cache resued
- prompt-based segmentation [attention-score ]





llava-1.5v-7b
Qwen2.5vl-3b [0.890/0.835]
Qwen2vl-2b 



今天：
- 理解rope编码
- 理解logic patch 编码



明天：
- 完成 rope编码修改
- 明晚开始微调

后天：
- 实现Qwen2vl-2b模型的accuracy



最晚
- 明天晚上开启 finetune
- 



ppt汇报选题：
- kv cache 缓存
- multimodal 结构
